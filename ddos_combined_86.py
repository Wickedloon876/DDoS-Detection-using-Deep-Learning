# -*- coding: utf-8 -*-
"""ddos-combined-86.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hNnOHooin8hSw1XZoh31oVjchfMsiOVd
"""

import pandas as pd
import numpy as np

from google.colab import drive
drive.mount('/content/drive')

df1 = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/data/MSSQL.csv",nrows=1000000)
df2 = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/data/Portmap.csv")
df3 = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/data/UDPLag.csv")

df = pd.concat([df1,df2,df3], axis=0)

df.head(5)

df = df.replace([np.inf, -np.inf], np.nan)
df.dropna(inplace=True)
df=df.drop_duplicates()
df.shape

df=df.drop_duplicates()
df=df.drop(' Destination IP', axis=1)
df=df.drop(' Source IP', axis=1)
df=df.drop('Flow ID', axis=1)
df=df.drop(' Timestamp', axis=1)
df=df.drop('Unnamed: 0', axis=1)
df=df.drop('SimillarHTTP', axis=1)
df.shape

print(df[' Label'].unique())

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df[' Label'] = le.fit_transform(df[' Label'])

print(df[' Label'].unique())

df[' Label'].value_counts()

X = df.iloc[:,:81]
y = df.iloc[:,-1]
X=X.values
X = X.reshape(X.shape[0], X.shape[1], 1)
y=y.values
from sklearn.model_selection import train_test_split 
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=101)

from keras.models import Sequential
from keras.layers import Dense, Conv1D, Flatten, MaxPooling1D
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn.datasets import load_iris
from numpy import unique

model = Sequential()
model.add(Conv1D(32, 3, activation="relu", input_shape=(81,1)))
model.add(Conv1D(64, 3, activation="relu"))
model.add(MaxPooling1D())
model.add(Dense(16, activation="relu"))
model.add(Flatten())
model.add(Dense(7, activation = 'softmax'))
model.compile(loss = 'sparse_categorical_crossentropy', optimizer = "adam", metrics = ['accuracy'])
model.summary()

H=model.fit(x=X_train,  
 y=y_train,
 epochs=10, 
 validation_split=0.1
  )

acc = model.evaluate(X_train, y_train)
print("Loss:", acc[0], " Accuracy:", acc[1])

pred = model.predict(X_test)
pred_y = pred.argmax(axis=-1)

cm = confusion_matrix(y_test, pred_y)
print(cm)